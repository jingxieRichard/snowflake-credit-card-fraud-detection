{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0549990d-647e-420f-a9d1-bb7cfdbc9b45",
   "metadata": {
    "collapsed": false,
    "name": "selectpackages"
   },
   "source": "# Credit Card Fraud Detection: Harnessing the Power of Machine Learning in Snowflake ML\n\nThe prerequisite for this notebook is the completion of setup in the other notebook.\n\nTo get started, let's select a few packages that we will need. In the **Packages** drop-down picker in the top right of the UI, search for and add the following packages by clicking on them:\n\n- snowflake-ml-python\n- matplotlib\n- seaborn: A python data visualzation library based on Matplotlib \n- altair: is a declarative statistical visualization library for Python that allows users to create informative and interactive visualizations with a focus on simplicity and clarity. \n\nOnce you add the packages, click the **Start** button! Once it says **Active**, you're ready to run the rest of the Notebook.\nWe will be consuming the features from the Feature Store\n\n### Snowflake ML Feature Store\nA Python SDK for defining, registering, retrieving, and managing features.\n\nEntity: Entities are the underlying objects that features and feature views are associated with. They encapsulate the join keys used for feature lookups. \n\nFeatureView: A feature view is a group of logically-related features that are refreshed on the same schedule.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "import_libs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Standard library imports \nimport os \nimport time \nimport math \n\n# Third-party libraries imports \nimport pandas as pd \nimport numpy as np \n\n# Snowflake libraries import \nimport streamlit as st \n\nimport altair as alt \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom snowflake.ml.feature_store import (\nFeatureStore, \nFeatureView, \nCreationMode\n)\n\nfrom snowflake.ml.registry import Registry \nfrom snowflake.ml.modeling.metrics import (\nroc_auc_score,\nprecision_score, \nrecall_score, \nconfusion_matrix\n)\nfrom snowflake.ml import dataset\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark.context import get_active_session\n\n\n# get the current session \nsession = get_active_session()\nsession.query_tag = {\n    \"origin\": \"sf_sit-is\",\n    \"name\": \"credit_card_fraud\",\n    \"version\": {\"major\": 1, \"minor\": 0},\n    \"attributes\": {\"is_quickstart\": 1, \"source\": \"notebook\"}\n}\n\n# Set the style for plots \nsns.set(style=\"whitegrid\")\n\n# Custom color palettes\ncolors = {\n    'Non-Fraud Bars': '#4C72B0',\n    'Fraud Bars': '#55A868',\n    'Non-Fraud Line': '#1f77b4',\n    'Fraud Line': '#ff7f0e'\n}\n"
  },
  {
   "cell_type": "markdown",
   "id": "47ab20eb-e582-459f-a151-c1aac537e229",
   "metadata": {
    "collapsed": false,
    "name": "set_contextfromprior"
   },
   "source": [
    "Set the context for the database and warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "set_context"
   },
   "outputs": [],
   "source": "session.sql(\"USE ROLE SYSADMIN\").collect()\nsession.sql(\"USE DATABASE CC_FINS_DB\").collect()\nsession.sql(\"USE SCHEMA ANALYTICS\").collect()"
  },
  {
   "cell_type": "markdown",
   "id": "f6adc03f-240a-47d5-b347-85c4d2966dd8",
   "metadata": {
    "collapsed": false,
    "name": "Spine_DF"
   },
   "source": [
    "Generating Datasets for Training\n",
    "We are now ready to generate our training set. We'll define a spine DataFrame to form the backbone of our generated dataset and pass it into FeatureStore.generate_dataset() along with our Feature Views.\n",
    "\n",
    "NOTE: The spine serves as a request template and specifies the entities, labels and timestamps (when applicable). The feature store then attaches feature values along the spine using an AS-OF join to efficiently combine and serve the relevant, point-in-time correct feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d975a-68a4-431d-b148-5669bb69a209",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_spine_df"
   },
   "outputs": [],
   "source": "session.sql(\"CREATE OR REPLACE TABLE TRANSACTIONS_DATA (USER_ID VARCHAR, TRANSACTION_ID VARCHAR (16777216), IS_FRAUD VARCHAR)\").collect()\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "44aaae1e-2d6e-4c3e-8044-a35f4beb235d",
   "metadata": {
    "collapsed": false,
    "name": "save_spinetransactions"
   },
   "source": [
    "Save the spine dataframe to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a534-2538-4499-bb79-6d24dc824bfc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "TRANSACTIONS_DATA"
   },
   "outputs": [],
   "source": "session.sql(\"INSERT INTO TRANSACTIONS_DATA(USER_ID, TRANSACTION_ID, IS_FRAUD) SELECT DISTINCT USER_ID, TRANSACTION_ID, IS_FRAUD FROM CREDITCARD_TRANSACTIONS\").collect()\nTRANSACTIONS_DATA_df = session.table(\"TRANSACTIONS_DATA\")\nTRANSACTIONS_DATA_df.show()"
  },
  {
   "cell_type": "markdown",
   "id": "581dae10-7515-4f63-beb2-a48aead752b0",
   "metadata": {
    "collapsed": false,
    "name": "stats_using_describe"
   },
   "source": "Descriptive statistics include those that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution.\n\n- Central tendency: \nRefers to the measure that identifies the center or typical value of a dataset. It indicates where most of the data points tend to cluster around. Three main meaures of central tendency: \n\n 1. Mean \n 2. Median \n 3. Mode: the value that appears most frequently in a dataset. Some datasets may have more than one mode (bimodal, multimodal), or none at all. \n\n -- Dispersion\n Also called variability or spread measures how much the data points deivate from the central tendency. It tells us about the spread of the data - whether the data points are close together or spread out. \n 1. Range: Range = Max - Min\n 2. Variance: \n 3. Standard deviation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d672cfd-b87b-48c0-a396-ebc9466bd33a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "stats"
   },
   "outputs": [],
   "source": "full_df = session.sql(\"SELECT * FROM CREDITCARD_TRANSACTIONS\")\nfull_df.describe()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7dbca-1884-4c9a-bb17-2eaee4e6d616",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "list_columns",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe18825-72ee-4af7-91ba-d7d4da91c794",
   "metadata": {
    "collapsed": false,
    "name": "Chart_fraud_normal"
   },
   "source": [
    "Visualization of the fraud and normal data using a bar chart displayed in Streamlit. Shows the total number of distinct transactions for each fraud category."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd041bb5-99f9-472c-a21e-aea7514a0cba",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "TRANSACTIONS_DATA_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533372f2-1c62-453d-8b9a-2e19660ee2f9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "visualization_stchart",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# Group by \"IS_FRAUD\" and count distinct TRANSACTION_ID\ndf = (TRANSACTIONS_DATA_df\n      .select(F.col(\"TRANSACTION_ID\"), F.col(\"IS_FRAUD\"))\n      .group_by(F.col(\"IS_FRAUD\"))\n      .agg(F.count_distinct(F.col(\"TRANSACTION_ID\")).alias(\"TOTAL_FRAUD\"))\n      )\ndf.show()\n\nst.bar_chart(df, x=\"IS_FRAUD\", y=\"TOTAL_FRAUD\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "ebe71034-909f-4a69-90c5-e306fd8e456c",
   "metadata": {
    "collapsed": false,
    "name": "transaction_amounts"
   },
   "source": [
    "Create a histogram that shows the distribution of transaction amounts, distinguishing between fraudulent and non-fraudulent transactions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ec496-bd4f-49ce-ad81-3a18e3089314",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DistributionofTransactionAmounts"
   },
   "outputs": [],
   "source": "# Load the dataset \ndataset = full_df.toPandas()\n\ndataset['IS_FRAUD'] = dataset['IS_FRAUD'].astype(int) \n\n# Set the style for the plots \nsns.set(style='whitegrid')\n# Background color \nbackground_color = \"#f0f0f0\"  # Light gray\n\n# 1. Distribution of Transaction Amounts\nplt.figure(figsize=(4,4))\nsns.histplot(data=dataset, x='TRANSACTION_AMOUNT', hue='IS_FRAUD', kde=True,bins=50)\nplt.title('Distribution of Transaction Amounts')\nplt.xlabel('Transaction Amount')\nplt.ylabel('Frequency')\nplt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\nplt.show()\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "43c88797-f7d3-4442-bfa7-1bcb46895f6d",
   "metadata": {
    "collapsed": false,
    "name": "dist_clicks"
   },
   "source": [
    "Create a histogram that shows the distribution of clicks, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4feee-00f6-4125-bbf0-31706ab2d6a3",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Clicksandlogins_Distribution"
   },
   "outputs": [],
   "source": [
    "#CLICKS, LOGIN_PER_HOUR, and PAGES_VISITED Distributions\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Custom color palettes\n",
    "colors = {\n",
    "    'Normal Bars': '#4C72B0',\n",
    "    'Fraud Bars': '#55A868',\n",
    "    'Normal Line': '#1f77b4',\n",
    "    'Fraud Line': '#ff7f0e'\n",
    "}\n",
    "# 4. CLICKS Distribution\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.histplot(data=dataset, x='CLICKS', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\n",
    "plt.title('Clicks Distribution')\n",
    "plt.xlabel('Clicks')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d72fe-553e-41fa-92e5-7c2883e0ffd6",
   "metadata": {
    "collapsed": false,
    "name": "dist_logins"
   },
   "source": [
    "Create a histogram that shows the distribution of logins, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434ffc9-cbd7-40de-9936-bcff3284554b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LOGIN_PER_HOUR"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "sns.histplot(data=dataset, x='LOGIN_PER_HOUR', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\n",
    "plt.title('Login Per Hour Distribution')\n",
    "plt.xlabel('Login Per Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ca0d1-afa7-4349-9b63-4a0b1df702ab",
   "metadata": {
    "collapsed": false,
    "name": "dist_timeelapsed"
   },
   "source": [
    "Create a histogram that shows the distribution of time elapsed, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbda17-190e-408d-a56b-960ec83fa40c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "TimeElapsedDistribution"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.histplot(data=dataset, x='TIME_ELAPSED', hue='IS_FRAUD', kde=True, bins=50)\n",
    "plt.title('Time Elapsed Distribution')\n",
    "plt.xlabel('Time Elapsed (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a06b3-3e26-4e68-987f-dadf9dfd01c7",
   "metadata": {
    "collapsed": false,
    "name": "dist_location"
   },
   "source": [
    "Create a histogram that shows the distribution of location, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fcc1c-478e-4f6d-9af6-b906384ac933",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Geographical_Distribution"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define location coordinates\n",
    "location_coords = {\n",
    "    'New York': (40.7128, -74.0060),\n",
    "    'Los Angeles': (34.0522, -118.2437),\n",
    "    'Chicago': (41.8781, -87.6298),\n",
    "    'Houston': (29.7604, -95.3698),\n",
    "    'Phoenix': (33.4484, -112.0740),\n",
    "    'Philadelphia': (39.9526, -75.1652),\n",
    "    'San Antonio': (29.4241, -98.4936),\n",
    "    'San Diego': (32.7157, -117.1611),\n",
    "    'Dallas': (32.7767, -96.7970),\n",
    "    'San Jose': (37.3382, -121.8863),\n",
    "    'Moscow': (55.7558, 37.6176)  # Add Moscow coordinates\n",
    "}\n",
    "\n",
    "# Add latitude and longitude based on location\n",
    "dataset['LATITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[0])\n",
    "dataset['LONGITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[1])\n",
    "\n",
    "# Filter for plotting\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot all locations\n",
    "scatter = plt.scatter(dataset['LONGITUDE'], dataset['LATITUDE'], \n",
    "                      c=dataset['IS_FRAUD'].map({0: 'purple', 1: 'red'}),\n",
    "                      alpha=0.5)\n",
    "\n",
    "# Create custom legend\n",
    "purple_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='purple', markersize=10, label='Normal')\n",
    "red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Fraud')\n",
    "\n",
    "# Plot details\n",
    "plt.title('Geographical Distribution of Transactions')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Set legend with custom handles\n",
    "plt.legend(handles=[purple_patch, red_patch], title='Transaction Type', loc='upper left', bbox_to_anchor=(1, 1), frameon=True, fontsize='small')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Set background color for the plot\n",
    "plt.gcf().set_facecolor(\"#f0f0f0\")  # Light gray\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f773b-8220-47bf-a10e-0206a8bb1ef9",
   "metadata": {
    "collapsed": false,
    "name": "FS_Init"
   },
   "source": [
    "## Feature Store\n",
    "The feature store contains feature views for customers and transactions. Model features will be accessed from the feature store.\n",
    "\n",
    "**Snowflake Feature:** Feature Store (PrPr) - Easily find features that work with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Feature_Store"
   },
   "outputs": [],
   "source": "# Access feature views \nfs = FeatureStore(\n    session=session,\n    database=\"CC_FINS_DB\",\n    name=\"ANALYTICS\",\n    default_warehouse=\"CC_FINS_WH\",\n    creation_mode=CreationMode.FAIL_IF_NOT_EXIST\n)\n\ncustomer_fv: FeatureView = fs.get_feature_view(\n    name='Customer_Features',\n    version='V9'\n)\nprint(customer_fv)\n\ntrans_fv: FeatureView = fs.get_feature_view(\n    name='Trans_Features',\n    version='V9'\n)\nprint(trans_fv)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56b86f-11bf-43a5-a8d5-994adfbdef3a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_dataset"
   },
   "outputs": [],
   "source": "# Get transactions dataset and get features from the feature store \ndef create_dataset(spine_df, name):\n    train_dataset = fs.generate_dataset(\n        name=name,\n        spine_df=spine_df,\n        features=[customer_fv, trans_fv]\n    )\n    df = train_dataset.read.to_snowpark_dataframe()\n    return df \n\n# Split into train/validation\ndatasets = TRANSACTIONS_DATA_df.random_split([.8, .2])\n\n# Build training tables \ntrain_df = create_dataset(datasets[0], \"train\")\nval_df = create_dataset(datasets[1], \"validation\")\n\ntrain_df.show(5)\nval_df.show(5)"
  },
  {
   "cell_type": "markdown",
   "id": "6aabcd42-980f-4e2b-9ed2-bf30779c9c95",
   "metadata": {
    "collapsed": false,
    "name": "training_dataset"
   },
   "source": [
    "View the training dataset.\n",
    "\n",
    "This contains the columns except for Ids. The Label is included here as this will be specified in the LABEL field during model training. The classification model supports numeric, Boolean, and string data types for features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b67a7-74d3-454b-9505-54d0732ba22e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "view_training_data"
   },
   "outputs": [],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a0b08-a8c7-462f-af04-15c0b75f9a10",
   "metadata": {
    "collapsed": false,
    "name": "view_creation"
   },
   "source": [
    "Creating separate views for training and validation to be used with a Binary Classifier. Columns in the inference data that were not present in the training dataset are ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5a892-8de4-44ee-946d-2fefe2671015",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_classification_view"
   },
   "outputs": [],
   "source": "train_df.write.mode(\"overwrite\").save_as_table(\"train_fd_table\")\nsession.sql(\"CREATE OR REPLACE VIEW FRAUD_CLASSIFICATION_TRAINING_VIEW AS SELECT IS_FRAUD, LATITUDE, LONGITUDE, LOCATION, TOTAL_TRANSACTIONS, STDDEV_TRANSACTION_AMOUNT, NUM_UNIQUE_MERCHANTS, MEAN_WEEKLY_SPENT, MEAN_MONTHLY_SPENT, MEAN_YEARLY_SPENT, TIME_ELAPSED, CLICKS, CUMULATIVE_CLICKS, CUMULATIVE_LOGINS_PER_HOUR FROM CC_FINS_DB.ANALYTICS.TRAIN_FD_TABLE\").collect()\n\nval_df.drop(\"IS_FRAUD\").collect()\nval_df.write.mode(\"overwrite\").save_as_table(\"val_fd_table\")\nsession.sql(\"CREATE OR REPLACE VIEW FRAUD_CLASSIFICATION_VAL_VIEW AS SELECT * EXCLUDE IS_FRAUD FROM val_fd_table\").collect()\n\n"
  },
  {
   "cell_type": "code",
   "id": "0b7d6a7c-f63e-40d3-8fa3-107dc3c2876e",
   "metadata": {
    "language": "python",
    "name": "Python_APP_Table",
    "collapsed": false
   },
   "outputs": [],
   "source": "# 1. Create or replace table CC_APP_TBL \n\nsession.sql(\"\"\"\n    CREATE OR REPLACE TABLE CC_APP_TBL AS \n    SELECT * FROM CREDITCARD_TRANSACTIONS \n    WHERE TRANSACTION_ID NOT IN \n    (SELECT DISTINCT TRANSACTION_ID FROM train_fd_table);\n\"\"\").collect()\n\n# 2. Alter the table to drop 'IS_FRAUD' column\nsession.sql(\"\"\"\n    ALTER TABLE CC_APP_TBL\n    DROP COLUMN IS_FRAUD;\n\"\"\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c341d-8098-47ec-afdd-4c93cac9f95b",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "APP_Table",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "/*\nCREATE or replace table CC_APP_TBL AS SELECT * FROM CREDITCARD_TRANSACTIONS WHERE TRANSACTION_ID NOT IN (SELECT DISTINCT TRANSACTION_ID FROM training_fd_table);\nalter table CC_APP_TBL drop column IS_FRAUD;\n*/"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5ee2a-959d-475d-8333-936ccb48500d",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "fraud_classification_val_view"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM fraud_classification_val_view LIMIT 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db877e6-45bd-4154-b3fb-f7ac40acb2bc",
   "metadata": {
    "collapsed": false,
    "name": "Build_model"
   },
   "source": "## Build the model\nWe can create the classification model by running the following statement\n\nRefer this link: https://docs.snowflake.com/en/user-guide/ml-functions/classification\n\n## About the Classification model \nThis classificstion function is powered by a gradient boosting machine. For binary classification, the model is trained using an area-under-the-curve loss function. For multi-class classification, the model is trained using a logistic loss function. \n\nSuitable training datasets for use with classification include a target column representing the labeled class of each data point and at least one feature column. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298e68c-89f9-410b-b778-0a428a0095b5",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_fraud_classification_model",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE SNOWFLAKE.ML.CLASSIFICATION fraud_classification_model(\n    INPUT_DATA => SYSTEM$REFERENCE('view', 'fraud_classification_training_view'),\n    TARGET_COLNAME => 'IS_FRAUD'\n);"
  },
  {
   "cell_type": "markdown",
   "id": "85c82676-7320-42ab-b523-6ac355dafaf6",
   "metadata": {
    "collapsed": false,
    "name": "view_classification_model"
   },
   "source": [
    "View all classification models, use the SHOW command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8fe61-4934-4846-beea-acf855dde9e8",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "show_classification"
   },
   "outputs": [],
   "source": [
    "SHOW SNOWFLAKE.ML.CLASSIFICATION;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e33e7a-8de7-4418-a46e-776b834f071c",
   "metadata": {
    "collapsed": false,
    "name": "fraud_detection"
   },
   "source": [
    "Run inference (prediction) on a dataset, use the modelâ€™s PREDICT method."
   ]
  },
  {
   "cell_type": "code",
   "id": "be98815f-3489-47d2-93e4-dbd8a6700eff",
   "metadata": {
    "language": "python",
    "name": "python_predict_fraud"
   },
   "outputs": [],
   "source": "session.sql(\"\"\"\n    CREATE OR REPLACE TABLE fraud_predictions AS \n    SELECT *, CC_FINS_DB.ANALYTICS.fraud_classification_model!PREDICT(INPUT_DATA => object_construct(*)) AS predictions\n    FROM fraud_classification_val_view\n\"\"\");",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a224d-6218-4aef-b8b0-abba597033fc",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "predict_fraud",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE fraud_predictions AS\nSELECT *,CC_FINS_DB.ANALYTICS.fraud_classification_model!PREDICT(INPUT_DATA => object_construct(*)) as predictions\nfrom fraud_classification_val_view;\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "86a8901b-b718-4841-85e5-e12848f80ed9",
   "metadata": {
    "collapsed": false,
    "name": "view_frauddetections"
   },
   "source": [
    "View the predictions.The model returns output in the following format. The prediction object includes predicted probabilities for each class and the predicted class based on the maximum predicted probability. The predictions are returned in the same order as the original features were provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1285fb-557b-4f94-b1c4-2e4add5c9394",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "view_predictions_table"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM fraud_predictions;"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf0da869-c73a-42a3-965b-beef9e70d3e6",
   "metadata": {
    "language": "python",
    "name": "show_prediction_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "model_pred = session.table(\"fraud_predictions\")\nmodel_pred = (model_pred\n             .with_column(\"class\", F.col(\"PREDICTIONS\")[\"class\"].cast(\"int\"))\n             .with_column(\"probability\",F.col(\"PREDICTIONS\")[\"probability\"])\n             .with_column(\"probability\", \n                          F.when(F.col(\"class\")==0, F.col(\"probability\")[\"0\"])\n                          .otherwise(F.col(\"probability\")[\"1\"])\n                         ))\nmodel_pred.show()\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "61823c63-bade-4dcc-8669-99a5fa3d9142",
   "metadata": {
    "collapsed": false,
    "name": "class_probabilities"
   },
   "source": [
    "In the result set, we see that the model produces both a predicted class denoted by class as well giving us the probability of the respective class membership. Oftentimes, we may want to parse out the probabilities or the prediction directly, and have it in its own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4cf5d-9c8c-4ab7-a024-173408f25e84",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "view_prediction"
   },
   "outputs": [],
   "source": [
    "select * EXCLUDE PREDICTIONS,\n",
    "        predictions:class::STRING AS class,\n",
    "      round(predictions['probability'][class], 3) as probability\n",
    "from fraud_predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f3b97-fcdb-4bf8-952b-8b2afd754519",
   "metadata": {
    "collapsed": false,
    "name": "ConfusionMatrix"
   },
   "source": [
    "Now that we have built our classifier, we can begin to evaluate it to better understand both its performance as well as the primary factors within the dataset that were driving the predictions. Follow along below to see the various commands you may run to evalute your own classifier:\n",
    "\n",
    "# Confusion Matrix & Model Accuracy\n",
    "One of the most common ways of evaluating a classifier is by creating a Confusion Matrix, which allows us to visualize the types of errors that the model is making. Typically, they are used to calculate a classifier's Precision & Recall; which describe both the accuracy of a model when it predicts a certain class of interest (Precision), as well as how many of that specific class of interest were classified (recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd67e8f-30ae-401f-95b6-f416801e63d7",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "SHOW_CONFUSION_MATRIX"
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_CONFUSION_MATRIX();"
  },
  {
   "cell_type": "markdown",
   "id": "3e39aff4-e6f3-4470-8c43-a7a364b45555",
   "metadata": {
    "collapsed": false,
    "name": "show_evaluation_metrics"
   },
   "source": [
    "The show_evaluation_metrics calculates the following False Positive, False Negative, True Positive and True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3b85e-1222-410e-8665-2b5b49a56bae",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "evaluation_metrics"
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_EVALUATION_METRICS();"
  },
  {
   "cell_type": "markdown",
   "id": "1d232ba1-6c00-4538-9346-23c1e6ded05e",
   "metadata": {
    "collapsed": false,
    "name": "show_threshold_metrics"
   },
   "source": "The show_threshold_metrics provides raw counts and metrics for a specific threshold for each class. This can be used to plot ROC and PR curves or do threshold tuning if desired. The threshold varies from 0 to 1 for each specific class; \n\nThe sample is classified as belonging to a class if the predicted probability of being in that class exceeds the specified threshold. \n* True Positive rate (TPR): The proportion of actual positive instances that the model correctly identifies (equivalent to Recall).\n* False positive rate (FPR): THe proportion of actual negative instances that were incorrectly predicted as positive. \n* Accuracy: \n* Support: The number of actual occurrences of a class in the specified dataset. Higher support values indicate a larger representation of a class in the dataset. Support is not itself a metric of the model but a characteristic of the dataset. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcb13a-7075-478c-b439-a0242ef07505",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "SHOW_THRESHOLD_METRICS"
   },
   "outputs": [],
   "source": "\nCALL fraud_classification_model!SHOW_THRESHOLD_METRICS();"
  },
  {
   "cell_type": "markdown",
   "id": "a69f3ff5-fee9-40a0-bc49-034ac3fab3f2",
   "metadata": {
    "collapsed": false,
    "name": "Feature_Importance"
   },
   "source": [
    "# Feature Importances\n",
    "The last thing we want to understand when evaluating the classifier is to get a sense of the importance of each of the individual input columns or features we made use of. \n",
    "\n",
    "Better understand what's driving a model's prediction to give us more insight into the business process we are trying to model out\n",
    "Engineer new features or remove ones that are not too impactful to increase the model's performance.\n",
    "The ML Classification function provides a method to do just this, and provides us a ranked list of the relative importance of all the input features, such that their values are between 0 and 1, and the importances across all the features sum to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3754281-6be9-4399-8771-34c77368fa57",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "show_featureimportance"
   },
   "outputs": [],
   "source": "\nCALL fraud_classification_model!SHOW_FEATURE_IMPORTANCE();"
  },
  {
   "cell_type": "markdown",
   "id": "7319e4d7-7516-4e5d-9270-fcac704774f1",
   "metadata": {
    "collapsed": false,
    "name": "Endofnotebook"
   },
   "source": [
    "This completes an end to end model building using Snowflake ML and detection of the fraud using a validation dataset."
   ]
  }
 ]
}